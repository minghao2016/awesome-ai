{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.345369Z",
     "start_time": "2019-01-28T18:16:06.095924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.constant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.364342Z",
     "start_time": "2019-01-28T18:16:07.347877Z"
    }
   },
   "outputs": [],
   "source": [
    "# constant is used to hold fixed numeric values\n",
    "node1 = tf.constant(3.0, tf.float32) # nodes are nothing but tensors\n",
    "node2 = tf.constant(4.5) # implicitly applied: float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.371167Z",
     "start_time": "2019-01-28T18:16:07.366338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Const_1:0' shape=() dtype=float32>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node1, node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.380839Z",
     "start_time": "2019-01-28T18:16:07.374113Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a session object to evaluate nodes\n",
    "with tf.Session() as sess:\n",
    "    sess.run(node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.389456Z",
     "start_time": "2019-01-28T18:16:07.383940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.5]\n"
     ]
    }
   ],
   "source": [
    "# you can evaluate multiple nodes at once\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.396403Z",
     "start_time": "2019-01-28T18:16:07.391467Z"
    }
   },
   "outputs": [],
   "source": [
    "node3 = tf.add(node1, node2) # add two nodes and assign to another node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.401992Z",
     "start_time": "2019-01-28T18:16:07.398211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.411801Z",
     "start_time": "2019-01-28T18:16:07.405258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n"
     ]
    }
   ],
   "source": [
    "# run the computation graph\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.placeholders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.419186Z",
     "start_time": "2019-01-28T18:16:07.413817Z"
    }
   },
   "outputs": [],
   "source": [
    "# placeholders are used to hold variable input\n",
    "a = tf.placeholder(tf.int32) # define the data type of the input\n",
    "b = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.425433Z",
     "start_time": "2019-01-28T18:16:07.420964Z"
    }
   },
   "outputs": [],
   "source": [
    "adder_node = tf.add(a, b) # add two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.435473Z",
     "start_time": "2019-01-28T18:16:07.428153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# evaluate computation graph\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(adder_node, feed_dict={a: 2, b: 4})) # use feed_dict to pass input to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.443468Z",
     "start_time": "2019-01-28T18:16:07.437196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 12]\n"
     ]
    }
   ],
   "source": [
    "# evaluate computation graph\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(adder_node, feed_dict={a:[1, 2], b:[3, 10]})) # pass multiple input to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.453306Z",
     "start_time": "2019-01-28T18:16:07.445090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  8 10]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(adder_node, feed_dict={a:[2, 3, 4], b:[4, 5, 6]}) # save the result into another node\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.458831Z",
     "start_time": "2019-01-28T18:16:07.455056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6,  8, 10], dtype=int32), (3,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.471849Z",
     "start_time": "2019-01-28T18:16:07.460811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable is used to hold values that keep changing during the process\n",
    "# variable maintains state in the graph across calls to run\n",
    "variable_a = tf.Variable(1.0, tf.float32)\n",
    "variable_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.484956Z",
     "start_time": "2019-01-28T18:16:07.473378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_b = tf.Variable([1.0, 2.0], tf.float32)\n",
    "variable_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass Over Linear Regression with Unit Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.532110Z",
     "start_time": "2019-01-28T18:16:07.486918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss =  41.0\n",
      "[2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "weight = tf.Variable([1.0], tf.float32) # set intial weight as 1.0\n",
    "bias = tf.Variable([1.0], tf.float32) # set initial weight as 1.0\n",
    "x = tf.placeholder(tf.float32) # unit feature\n",
    "\n",
    "model = weight * x + bias # vectorize linear model\n",
    "\n",
    "# create placeholder for predicted value\n",
    "y_original = tf.placeholder(tf.float32)\n",
    "\n",
    "# create a error metric\n",
    "error_measure = tf.squared_difference(model, y_original)\n",
    "\n",
    "# create a loss function\n",
    "loss_function = tf.reduce_mean(error_measure)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # now run to evaluate the loss function\n",
    "    print(\"Loss = \", sess.run(loss_function, feed_dict={x:[1, 2, 3, 4], y_original:[-1, -2, -3, -4]}))\n",
    "    # predict\n",
    "    print(sess.run(model, feed_dict={x:[1, 2, 3, 4], y_original:[-1, -2, -3, -4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration Using Another Weight and Bias Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.580507Z",
     "start_time": "2019-01-28T18:16:07.536468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss =  0.0\n",
      "[-1. -2. -3. -4.]\n"
     ]
    }
   ],
   "source": [
    "# now lets change weight and bais\n",
    "weight = tf.Variable([-1.0], tf.float32) # set intial weight as 1.0\n",
    "bias = tf.Variable([0.0], tf.float32) # set initial weight as 1.0\n",
    "x = tf.placeholder(tf.float32) # unit feature\n",
    "\n",
    "model = weight * x + bias # vectorize linear model\n",
    "\n",
    "# create placeholder for predicted value\n",
    "y_original = tf.placeholder(tf.float32)\n",
    "\n",
    "# create a error metric\n",
    "error_measure = tf.squared_difference(model, y_original)\n",
    "\n",
    "# create a loss function\n",
    "loss_function = tf.reduce_mean(error_measure)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # now run to evaluate the loss function\n",
    "    print(\"Loss = \", sess.run(loss_function, feed_dict={x:[1, 2, 3, 4], y_original:[-1, -2, -3, -4]}))\n",
    "    # predict\n",
    "    print(sess.run(model, feed_dict={x:[1, 2, 3, 4], y_original:[-1, -2, -3, -4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Linear Regression With Unit Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.586784Z",
     "start_time": "2019-01-28T18:16:07.582693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(100))\n",
    "a[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.593506Z",
     "start_time": "2019-01-28T18:16:07.588621Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dummy data for now\n",
    "# training data\n",
    "x_train = np.array(range(0, 10)).reshape((10, 1))\n",
    "y_train = x_train * 2\n",
    "\n",
    "# validation data\n",
    "x_val = np.array(range(80, 100)).reshape((20, 1))\n",
    "y_val = x_val * 2\n",
    "\n",
    "# test data\n",
    "x_test = np.array([0, -1, 100]).reshape((3, 1))\n",
    "y_test = np.array([0, -2, 200]).reshape((3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:07.667947Z",
     "start_time": "2019-01-28T18:16:07.595507Z"
    }
   },
   "outputs": [],
   "source": [
    "# first set some initial values for weight and bias: same as before\n",
    "weight = tf.Variable([0.0], dtype=tf.float64)\n",
    "bias = tf.Variable([0.0], dtype=tf.float64)\n",
    "\n",
    "x = tf.placeholder(tf.float64) # placeholder\n",
    "y = tf.placeholder(tf.float64)\n",
    "\n",
    "linear_model = tf.add(tf.multiply(weight, x), bias) # model\n",
    "\n",
    "loss_function = tf.reduce_mean(tf.square(tf.subtract(linear_model, y))) # minimize the loss function = mean squared difference\n",
    "\n",
    "alpha = tf.constant(0.01) # set fixed learning rate\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=alpha) # use an optimizer to optimize the weights and bias\n",
    "\n",
    "# use the optimizer to minimise the loss function\n",
    "trainer = optimizer.minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:16:08.107478Z",
     "start_time": "2019-01-28T18:16:07.670224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Validation Loss =  5921.296152321758\n",
      "Weights =  [1.13999997]\n",
      "Bias =  [0.18]\n",
      "\n",
      "Validation Loss =  5.4553371056449595\n",
      "Weights =  [1.97200412]\n",
      "Bias =  [0.17555058]\n",
      "\n",
      "Validation Loss =  1.7575809387018708\n",
      "Weights =  [1.98410937]\n",
      "Bias =  [0.09964354]\n",
      "\n",
      "Validation Loss =  0.566251121840238\n",
      "Weights =  [1.99098039]\n",
      "Bias =  [0.05655826]\n",
      "\n",
      "Validation Loss =  0.18243275511520562\n",
      "Weights =  [1.99488041]\n",
      "Bias =  [0.0321028]\n",
      "\n",
      "Validation Loss =  0.058775530599852285\n",
      "Weights =  [1.99709409]\n",
      "Bias =  [0.01822174]\n",
      "\n",
      "Validation Loss =  0.018936089602506995\n",
      "Weights =  [1.99835059]\n",
      "Bias =  [0.01034276]\n",
      "\n",
      "Validation Loss =  0.006100761418479013\n",
      "Weights =  [1.99906379]\n",
      "Bias =  [0.00587061]\n",
      "\n",
      "Validation Loss =  0.001965521428471433\n",
      "Weights =  [1.9994686]\n",
      "Bias =  [0.00333219]\n",
      "\n",
      "Validation Loss =  0.0006332446428873661\n",
      "Weights =  [1.99969837]\n",
      "Bias =  [0.00189137]\n",
      "\n",
      "Testing...\n",
      "Test Loss =  8.772327361863822e-05\n",
      "Prediction =  [[ 1.07965162e-03]\n",
      " [-1.99874817e+00]\n",
      " [ 1.99983862e+02]]\n",
      "Original Values =  [[  0]\n",
      " [ -2]\n",
      " [200]]\n"
     ]
    }
   ],
   "source": [
    "# run the mode\n",
    "with tf.Session() as sess:\n",
    "    print(\"Training...\")\n",
    "    sess.run(tf.global_variables_initializer()) # initialize variables\n",
    "    # run the optimizer for 1000 iterations\n",
    "    for i in range(1000):\n",
    "        sess.run(trainer, feed_dict={x:x_train, y:y_train})\n",
    "        # print(\"Train Loss = \", sess.run(loss_function, feed_dict={x:x_train, y:y_train}))\n",
    "        if i % 100 == 0:\n",
    "            print(\"Validation Loss = \", sess.run(loss_function, feed_dict={x:x_val, y:y_val}))\n",
    "            print(\"Weights = \", sess.run(weight))\n",
    "            print(\"Bias = \", sess.run(bias))\n",
    "            print()\n",
    "    # now perform prediction\n",
    "    print(\"Testing...\")\n",
    "    print(\"Test Loss = \", sess.run(loss_function, feed_dict={x:x_test, y:y_test}))\n",
    "    print(\"Prediction = \", sess.run(linear_model, feed_dict={x:x_test})) # expected values are in y_test\n",
    "    print(\"Original Values = \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that we didnt get the exact value but its very close and error has been reduced drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_env]",
   "language": "python",
   "name": "conda-env-ai_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
