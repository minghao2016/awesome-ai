{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.473178Z",
     "start_time": "2019-03-03T16:54:15.390108Z"
    }
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding of characters\n",
    "----\n",
    "\n",
    "One-hot encoding is the most common, most basic way to turn a token into a vector. It consists in associating a unique integer index to every character, then \n",
    "turning this integer index i into a binary vector of size N, the size of the vocabulary, that would be all-zeros except for the i-th \n",
    "entry, which would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.479005Z",
     "start_time": "2019-03-03T16:54:15.475806Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample set to work with\n",
    "samples = [\"The cat sat on the mat.\", \"The dog ate my homework.\", \"I am writing code in Python.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.495600Z",
     "start_time": "2019-03-03T16:54:15.483148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = string.printable # get all ascii characters\n",
    "len(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.504203Z",
     "start_time": "2019-03-03T16:54:15.499086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', 'a', '\\x0c')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[0], characters[10], characters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.516954Z",
     "start_time": "2019-03-03T16:54:15.508228Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a mapping for each character\n",
    "token_index = dict(zip(characters, range(len(characters))))\n",
    "len(token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.524662Z",
     "start_time": "2019-03-03T16:54:15.520991Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 100 # max number of characters allowed for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.532658Z",
     "start_time": "2019-03-03T16:54:15.527664Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create character embedding\n",
    "one_hot_encoded = np.zeros(shape=(len(samples), max_len, len(token_index))) # numpy array to store character embedding\n",
    "for i, sample in enumerate(samples):\n",
    "    # for each sample, acces each character\n",
    "    for j, char in enumerate(sample):\n",
    "        # get the index of the character\n",
    "        encoding_value = token_index[char]\n",
    "        # assign index value to that character\n",
    "        one_hot_encoded[i, j, encoding_value] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.540346Z",
     "start_time": "2019-03-03T16:54:15.535343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('number of samples, number total characters allowed per sample, char embedding dim = ',\n",
       " (3, 100, 100))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"number of samples, number total characters allowed per sample, char embedding dim = \", one_hot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.549465Z",
     "start_time": "2019-03-03T16:54:15.542089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded[0][1] # first samples, first char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T16:54:15.559509Z",
     "start_time": "2019-03-03T16:54:15.552784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded[0][2] # first samples, second char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, you have your character embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_env]",
   "language": "python",
   "name": "conda-env-ai_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
