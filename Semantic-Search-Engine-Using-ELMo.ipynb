{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:30:53.328781Z",
     "start_time": "2019-02-01T14:30:52.785287Z"
    }
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_sm\") # load english vocab\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ELMo Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:34.898809Z",
     "start_time": "2019-02-01T14:11:34.163135Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\" # elmo model\n",
    "embedding = hub.Module(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:35.976245Z",
     "start_time": "2019-02-01T14:11:34.900445Z"
    }
   },
   "outputs": [],
   "source": [
    "que_df = pd.read_csv(\"../DATAHUB/quora-dataset/question-pair-dataset.csv\") # load data\n",
    "que_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:35.993726Z",
     "start_time": "2019-02-01T14:11:35.979552Z"
    }
   },
   "outputs": [],
   "source": [
    "que_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:36.882740Z",
     "start_time": "2019-02-01T14:11:35.997539Z"
    }
   },
   "outputs": [],
   "source": [
    "# consider only one set of questions\n",
    "que_df[\"processed_q1\"] = que_df.question1.apply(lambda sent: re.sub(\"[^a-z0-9.?! ]\", \"\", str(sent).strip().lower()))\n",
    "que_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:55.665399Z",
     "start_time": "2019-02-01T14:11:55.635941Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = list(que_df.processed_q1)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:56.832558Z",
     "start_time": "2019-02-01T14:11:56.828819Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:59.288525Z",
     "start_time": "2019-02-01T14:11:59.278188Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = sentences[:1000] # for quich training, will select only about 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ELMo Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:12:02.188242Z",
     "start_time": "2019-02-01T14:12:01.672886Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = embedding(sentences, signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:13:43.484961Z",
     "start_time": "2019-02-01T14:12:04.449736Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate embeddings for each question\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    x = sess.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:14:39.812866Z",
     "start_time": "2019-02-01T14:14:39.808394Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:18:07.913945Z",
     "start_time": "2019-02-01T14:18:07.474741Z"
    }
   },
   "outputs": [],
   "source": [
    "# initiate pca for 50 components\n",
    "pca = PCA(n_components=50)\n",
    "y = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:19:32.634126Z",
     "start_time": "2019-02-01T14:19:24.382355Z"
    }
   },
   "outputs": [],
   "source": [
    "# use t-sne to compress 50 components into 2\n",
    "z = TSNE(n_components=2).fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings In HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:24:31.480993Z",
     "start_time": "2019-02-01T14:24:31.137308Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:27:12.983829Z",
     "start_time": "2019-02-01T14:27:12.194163Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    go.Scatter(\n",
    "        x = [i[0] for i in z],\n",
    "        y = [i[1] for i in z],\n",
    "        mode = \"markers\",\n",
    "        text=[i for i in sentences],\n",
    "        marker=dict(\n",
    "            size=16,\n",
    "            color = [len(i) for i in sentences], #set color equal to a variable\n",
    "            opacity= 0.8,\n",
    "            colorscale=\"Viridis\",\n",
    "            showscale=False\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout()\n",
    "\n",
    "layout = dict(\n",
    "    yaxis = dict(zeroline = False),\n",
    "    xaxis = dict(zeroline = False)\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "file = plot(fig, filename=\"Sentence_Embedding.html\") # new tabs open and see the interactive visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:39:48.880323Z",
     "start_time": "2019-02-01T14:39:07.569655Z"
    }
   },
   "outputs": [],
   "source": [
    "results_returned = \"3\" # show top 3 results\n",
    "\n",
    "\n",
    "while input_sentence != \"done\":\n",
    "    # take input sentence\n",
    "    input_sentence = input(\"Search Query:\", )\n",
    "\n",
    "    instance_embd = embedding([input_sentence], signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        search_vect = sess.run(instance_embd)\n",
    "\n",
    "    cosine_similarities = pd.Series(cosine_similarity(search_vect, x).flatten()) # find the similarity\n",
    "\n",
    "    output = \"\"\n",
    "\n",
    "    for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
    "        output += \"<p style='font-family:verdana; font-size:110%; color:yellow'> \"\n",
    "        for i in sentences[i].split():\n",
    "            if i.lower() in input_sentence:\n",
    "                output += \" <b>\" + str(i) + \"</b>\"\n",
    "            else:\n",
    "                output += \" \"+str(i)\n",
    "        output += \"</p><hr>\"\n",
    "    output = \"<h3>Results: </h3>\" + output\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't go with the performance since the training is done on a very small dataset due to computation constraints. It's a POC to show that symantic search can be done using ELMo. A better training data and enough computation can do the magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_env]",
   "language": "python",
   "name": "conda-env-ai_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
